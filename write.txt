1.写入流程概要流程：

写入流程可以分为以下三步：

将解析后的记录( key-value )写入到 WriteBatch
将WAL日志写入log文件
将WriteBatch中的内容写到memtable中，事务完成
其中，2、3 两步在 commit 阶段完成。

在 MyRocks 中，复用了 MySQL 的主从同步流程，因此，在开启 binlog 的情况下，还需要写入 binlog。


2.insert流程
mysql_execute_command
--mysql_insert
----write_record
------handler::ha_write_row
--------myrocks::ha_rocksdb::write_row
----------myrocks::ha_rocksdb::skip_unique_check
----------myrocks::ha_rocksdb::update_write_row//!!!!!!!!!!!!!!!!!!!
------------myrocks::get_or_create_tx
--------------get_tx_from_thd
----------------thd_ha_data
------------------thd->ha_data[hton->slot].ha_ptr
--------------new Rdb_writebatch_impl(thd);//slave
--------------new Rdb_transaction_impl(thd);
--------------start_tx
----------------rdb->BeginTransaction(write_opts, tx_opts, m_rocksdb_reuse_tx);
------------myrocks::ha_rocksdb::get_pk_for_update
--------------rocksdb::update_hidden_pk_val
------------myrocks::ha_rocksdb::check_uniqueness_and_lock
--------------myrocks::ha_rocksdb::check_and_lock_unique_pk
----------------get_for_update
------------------TransactionBaseImpl::GetForUpdate
--------------------PessimisticTransaction::TryLock
------------myrocks::ha_rocksdb::update_indexes
--------------myrocks::ha_rocksdb::update_pk
----------------myrocks::ha_rocksdb::convert_record_to_storage_format
----------------myrocks::Rdb_transaction_impl::put
------------------rocksdb::TransactionBaseImpl::Put
--------------------rocksdb::PessimisticTransaction::TryLock
----------------------rocksdb::TransactionBaseImpl::SetSnapshotIfNeeded
----------------------rocksdb::TransactionBaseImpl::TrackKey//把所有的锁，保存到map里
------------------------rocksdb::TransactionBaseImpl::TrackKey
--------------------rocksdb::TransactionBaseImpl::GetBatchForWrite

------------myrocks::ha_rocksdb::do_bulk_commit//myrocks::ha_rocksdb::update_write_row end !!!!!!!!!!!!!!!!
--------------myrocks::ha_rocksdb::commit_in_the_middle
----------binlog_log_row

3.myrocks各种写操作。
插入操作比较好理解，直接写入writebatch就可 以了。

 删除操作在writebatch里本质上也是写入，只不过是标记了待删除的key。

 对应到Myrocks，如果更新主键或二级索引（RocksDB的key区域），会删除原有记录，插入新纪录，其他情况会直接插入新数据不会删除原有的数据。
 
 在具体写入数据时，会先写WAL日志，然后将key-value插入Memtable，Memtable满了或者其他条件被触发后会构造新的Memtable，并将老的Memtable转化为只读的immutable Memtable。immutable Memtable达到一定数量后需要刷盘成为SStable，初始层号为L0，后期L0还将通过compact向高层级合
并。

以上就是RocksDB在LSM数理论上的实现逻辑。下面我们透过代码来看具体实现。选用的版本为github/facebook/rocksdb，2018年7月11日版本（commit：35b38a232c1d357a7a885b9b4b8442e24a8433d7 ）

4.总体模块划分
我们可以将实现过程大致抽象为：外部接口层、数据库逻辑层、WriteBatch层、Memtable层，再往下还有跳表层操作，以及后续的Memtable切换和Flush到SStable等操作。

5.对外接口
RocksDB 对外提供了Get(key), Put(key), Delete(key) and NewIterator()等操作，我们可以直接从官方的文档里面找到测试程序，以此为入口开始代码分析（examples/c_simple_example.c）。

c_simple_example
--rocksdb_open
----DB::Open(options->rep, std::string(name), &db)
------DBImpl::Open
--rocksdb_writeoptions_create
--rocksdb_put
----db->rep->Put(options->rep, Slice(key, keylen), Slice(val, vallen)
/*
  // Pre-allocate size of write batch conservatively.
  // 8 bytes are taken by header, 4 bytes for count, 1 byte for type,
  // and we allocate 11 extra bytes for key length, as well as value length.
*/
------DB::Put
--------WriteBatch::Put
----------WriteBatchInternal::Put
------------PutLengthPrefixedSlice(&b->rep_, key);
------------PutLengthPrefixedSlice(&b->rep_, value);
--------DBImpl::Write
----------DBImpl::WriteImpl

代码中的rocksdb_put、rocksdb_get作为全局函数调用DB::put/DB:get接口，本质是调用的数据库实现类DBImpl的操作。
其中key和value被打包成slice对象传入put接口，写入WriteBatch::rep_(要么都提交，要么都回滚)，后续将批量写入Memtable。

Slice由一个size变量和一个指向外部内存区域的指针构成。使用slice可以减少之后的key、value在传值过程中的拷贝操作。
writeoptions是写的配置信息，明确是否需要写日志以及是否需要关闭异步写等参数选项。

6.数据库实现层逻辑
每次写请求并不是直接读写Memtable的，而是打包进Writer等待批量写入的，这样的一个重要意义是可以使得一个事务内的的操作一次性写入数据和维护版本等信息。
后续多个线程的Writer会组成一个Group，并选出第一个为leader，以组的形式完成日志提交和Memtable写入。


RocksDB的维护和更新非常及时。几个有代表的优化和新功能是：pipelinewrite、concurrent_memtable_write、2pc状态下的concurrent_WriteToWAL。随着新功能的增加，在数据库层的代码逻辑也越来越复杂，分支非常多。

总的来说rocksdb会将多个写线程组成一个group，leader负责 group内所有writer的WAL及memtable的提交，提交完后唤醒所有的follwer，向上层返回。
后续更新支持 allow_concurrent_memtable_write 选项，在之前的基础上，leader提交完WAL后，group里所有线程并发写 memtable，流程如下图。

而 enable_pipelined_write 选项，引入了流水线特性，第一个 group 的 WAL 提交后，在执行 memtable 写入前，下一个 group 同时开启。

DBImpl::WriteImpl
--//if enable_pipelined_write
----WriteThread::Writer w(write_options, my_batch, callback, log_ref,disable_memtable, pre_release_callback);
----WriteThread::JoinBatchGroup(&w);
------linked_as_leader = LinkOne(w, &newest_writer_);
------if (linked_as_leader) {
        SetState(w, STATE_GROUP_LEADER);
      }    
------if (!linked_as_leader) {
        /**
         * Wait util:
         * 1) An existing leader pick us as the new leader when it finishes
         * 2) An existing leader pick us as its follewer and
         * 2.1) finishes the memtable writes on our behalf
         * 2.2) Or tell us to finish the memtable writes in pralallel
         * 3) (pipelined write) An existing leader pick us as its follower and
         *    finish book-keeping and WAL write for us, enqueue us as pending
         *    memtable writer, and
         * 3.1) we become memtable writer group leader, or
         * 3.2) an existing memtable writer group leader tell us to finish memtable
         *      writes in parallel.
         */
        AwaitState(w, STATE_GROUP_LEADER | STATE_MEMTABLE_WRITER_LEADER |
                          STATE_PARALLEL_MEMTABLE_WRITER | STATE_COMPLETED,
                   &jbg_ctx);
      } 
----//if (w.state == WriteThread::STATE_PARALLEL_MEMTABLE_WRITER)
------WriteBatchInternal::InsertInto
------write_thread_.CompleteParallelMemTableWriter(&w)
--------AwaitState(w, STATE_COMPLETED, &cpmtw_ctx);
------write_thread_.ExitAsBatchGroupFollower(&w); 

----//if (w.state == WriteThread::STATE_COMPLETED)
------ return w.FinalStatus();

----//if w.state == WriteThread::STATE_GROUP_LEADER
------write_thread_.EnterAsBatchGroupLeader// 把次leader下所有writer都链接到一个writegroup中
------//if (!two_write_queues_)
--------WriteToWAL
------//if (two_write_queues_)
--------ConcurrentWriteToWAL
------//if (!parallel)//非并发写
--------WriteBatchInternal::InsertInto
------// if (parallel) 并发写


--//if not enable_pipelined_write



